
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lineare Regression</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/UtilityCode/__pycache__/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Tidy Data" href="S06a_TidyData.html" />
    <link rel="prev" title="Testen von Hypothesen" href="S04a_Estimation%26HyptothesisTesting.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/datascience.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Dieses Buch durchsuchen ..." aria-label="Dieses Buch durchsuchen ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Vorwort.html">
   Vorwort
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  01 Einleitung
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_01/Einleitung.html">
   Einleitung
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../chapter_01/Fallstudie.html">
   Fallstudie
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter_01/Introduction_Fallstudie.html">
     Wie riskant sind Aktien?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../chapter_01/Umsetzung_Fallstudie.html">
     Umsetzung in Python
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  02 Python Part 1
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_02/Intro_JupyterNotebooks.html">
   Einführung in Jupyter Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_02/Intro_Python.html">
   Einführung in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_02/Intro_Modules.html">
   Module nutzen
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  99 Analytics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="S02a_Descriptive_Statistics.html">
   Deskriptive Statistik
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="S03a_Simulation.html">
   Simulationen mit Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="S03c_Probability_Distributions.html">
   Wahrscheinlichkeitsverteilungen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="S04a_Estimation%26HyptothesisTesting.html">
   Testen von Hypothesen
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Lineare Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="S06a_TidyData.html">
   Tidy Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="S07a_Classification.html">
   Klassifikation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="S08a_Clustering.html">
   Clusteranalyse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="S09a_Cross_validation.html">
   Cross Validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="S11_DecisionTrees.html">
   Entscheidungsbäume
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="S12_Ensembles.html">
   Ensemble-Methoden
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Anhang
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../literatur.html">
   Literatur
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Navigation umschalten" aria-controls="site-navigation"
                title="Navigation umschalten" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Laden Sie diese Seite herunter"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/chapters/chapter_analytics/S05a_Regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Quelldatei herunterladen" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="In PDF drucken"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Vollbildmodus"
        title="Vollbildmodus"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/fredzett/Skript-Business-Analytics/master?urlpath=tree/chapters/chapter_analytics/S05a_Regression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Starten Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/fredzett/Skript-Business-Analytics/blob/master/chapters/chapter_analytics/S05a_Regression.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Starten Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Inhalt
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-formulation">
   Model formulation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimation-of-regression-function">
   Estimation of regression function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simple-linear-regression">
     Simple linear regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiple-regression">
     Multiple regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation-of-regression-function">
   Evaluation of regression function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-assessment-of-regression-model">
     Global assessment of regression model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#assessment-of-regression-coefficients">
     Assessment of regression coefficients
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#validating-model-assumptions">
   Validating model assumptions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-linearity">
   Non-linearity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interaction-effects">
   Interaction effects
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dealing-with-qualitative-data">
   Dealing with qualitative data
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Lineare Regression</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Inhalt </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-formulation">
   Model formulation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimation-of-regression-function">
   Estimation of regression function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simple-linear-regression">
     Simple linear regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multiple-regression">
     Multiple regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation-of-regression-function">
   Evaluation of regression function
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-assessment-of-regression-model">
     Global assessment of regression model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#assessment-of-regression-coefficients">
     Assessment of regression coefficients
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#validating-model-assumptions">
   Validating model assumptions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-linearity">
   Non-linearity
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#interaction-effects">
   Interaction effects
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dealing-with-qualitative-data">
   Dealing with qualitative data
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="lineare-regression">
<h1>Lineare Regression<a class="headerlink" href="#lineare-regression" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">Datasets</span><span class="p">,</span> <span class="n">make_y_X</span>
<span class="kn">from</span> <span class="nn">patsy</span> <span class="kn">import</span> <span class="n">dmatrices</span>
</pre></div>
</div>
</div>
</div>
<p>The following chapter is based on <a class="reference external" href="https://www.springer.com/de/book/9783662460764"><em>Backhaus et al (2017)</em></a>.</p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>Linear regresssion is one of the most flexibel and widely used statistical methods used in research. It is used for analysing the relationship between a <strong>dependent</strong> and one or more <strong>independent</strong> variables. Linear regression is used for</p>
<ol class="simple">
<li><p><strong>inference</strong>, i.e. to test a prior developed hypothesis about the relationship between variables of interest</p></li>
<li><p><strong>prediction</strong>, i.e. to estimate the value of a dependent variable given values of independent variables</p></li>
</ol>
<p>Primary use case for linear regression analysis is the analysis of <strong>causal relations</strong>. This relation can be expressed as</p>
<div class="math notranslate nohighlight">
\[Y = f(X)\]</div>
<p><strong>Simple (linear) regresssion:</strong></p>
<p>If we want to express that there we believe in a relation between <em>revenues</em> and <em>price</em> we may state this as</p>
<div class="math notranslate nohighlight">
\[\text{revenues} = f(\text{price})\]</div>
<p>Using linear regression this <strong>relation can be quantified</strong>, i.e. we can determine how much <em>revenue</em> will change if we change <em>price</em>.</p>
<p><strong>Stochastic model:</strong><br />
It is very unlikely that the the relation between the above variables is entirely deterministic (as assumed in the above formula). We, therefore, need to introduce uncertainty to the model. The resulting <strong>stochastic model</strong> is commonly used in regression analysis and is described as:</p>
<div class="math notranslate nohighlight">
\[Y = f(X) + \epsilon\]</div>
<p>Here <span class="math notranslate nohighlight">\(\epsilon\)</span> is a <strong>random variable</strong> (called error term / residual) which cannot be observed and is assumed to follow a standard normal distribution (i.e. <span class="math notranslate nohighlight">\(\epsilon \sim N(0,1)\)</span>). The stochastic model will be required to <strong>evaluate the regression models using statistical tests</strong>.</p>
<p><strong>Multiple (linear) regression:</strong><br />
In many (if not most) research questions we may not assume a monocausal relationship. Instead <span class="math notranslate nohighlight">\(Y\)</span>, our variable we want to analyse, is influenced by numerous factors. In our above example <em>revenues</em> may also depend on advertising spent but also from other factor such as the state of the economy, the price, behaviour of competitors etc.</p>
<p>For such a relationship we use a <strong>multiple regression analysis</strong> which may be expressed as:</p>
<div class="math notranslate nohighlight">
\[Y = f(X_1, X_2, \ldots, X_J)\]</div>
<p><strong>Causality vs. correlation:</strong><br />
It is important to state that while we attempt to model a causal relationship between <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X\)</span>, in practice we cannot determine whether or not the relationship is actually causal. Instead all we do is we approximate causality be assessing correlation.</p>
<p><strong>Typical hypotheses modelled with linear regression</strong></p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>#</p></th>
<th class="head"><p>Hypothesis</p></th>
<th class="head"><p>Dependent variable</p></th>
<th class="head"><p>Independent variable</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>Is revenue by salesperson dependent on number of customer visits?</p></td>
<td><p>Revenue per sales person (per period)</p></td>
<td><p>Number of customer visits per sales person (per period)</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>Will sales change if advertising spent is doubled</p></td>
<td><p>Sales per period</p></td>
<td><p>Spent on advertisment per period</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>How does a price increase of x% impact sales if advertisment spent is   increased by 10% at the same time</p></td>
<td><p>Sales per period</p></td>
<td><p>Advertisment spent, price, …</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="model-formulation">
<h2>Model formulation<a class="headerlink" href="#model-formulation" title="Permalink to this headline">¶</a></h2>
<p>A model is a simplified representation of reality. Models are very useful but it is always a fine line between simplification and complexity. If we want to model reality as close as possible our model may become to complex. If our model is to simple it may not describe reality good enough for our purposes. There is no such thing as a good or a bad model. It is more helpful to think of a model as suitable or not suitable for our problem at hand. It turns out the linear regression models are quite simple yet very suitable for many research and practical problems which is why they are heavily relied on in all social sciences.</p>
<blockquote>
<div><p><strong>Dataset</strong>: In the following we will be using the advertising dataset from <a class="reference external" href="http://faculty.marshall.usc.edu/gareth-james/ISL/index.html">Introduction to Statistical Learning</a> for the following examples. The dataset contains</p>
<ul class="simple">
<li><p>sales in thousands units</p></li>
<li><p>advertising budgets in thousand of dollars for TV, radio and newspaper</p></li>
</ul>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">Datasets</span><span class="o">.</span><span class="n">advertising</span><span class="p">(</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span> <span class="c1"># load advertisment data</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># show first 5 rows of data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TV</th>
      <th>radio</th>
      <th>newspaper</th>
      <th>sales</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>230.1</td>
      <td>37.8</td>
      <td>69.2</td>
      <td>22.1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>44.5</td>
      <td>39.3</td>
      <td>45.1</td>
      <td>10.4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17.2</td>
      <td>45.9</td>
      <td>69.3</td>
      <td>9.3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>151.5</td>
      <td>41.3</td>
      <td>58.5</td>
      <td>18.5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>180.8</td>
      <td>10.8</td>
      <td>58.4</td>
      <td>12.9</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>Sales vs. TV advertisment spent:</strong><br />
Let us assume that we believe in a simple linear relation between <strong>sales</strong> and <strong>TV</strong> advertisment spent. We can describe this as</p>
<div class="math notranslate nohighlight">
\[\text{sales} = f(\text{TV})\]</div>
<p>This implies that we believe in a causal relationship between both variables. Specifically we believe that <em>TV</em> advertisment spent drives or influences <em>sales</em>.</p>
<p><strong>Regression function:</strong></p>
<p>A simple linear regression model of the above formulations could be:</p>
<div class="math notranslate nohighlight">
\[\hat{Y} = \hat{\beta}_0 + \hat{\beta}_1X \]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{Y}\)</span> denotes the prediction of the dependent variable <span class="math notranslate nohighlight">\(Y\)</span> given <span class="math notranslate nohighlight">\(X\)</span>. <span class="math notranslate nohighlight">\(\hat{\beta}_0\)</span> and <span class="math notranslate nohighlight">\(\hat{\beta}_1\)</span> are the coefficient estimates.</p>
<p>For our example the regression function looks as follows:</p>
<div class="math notranslate nohighlight">
\[\text{sales} = \hat{\beta}_0 + \hat{\beta}_1\text{TV}\]</div>
<p>Given the mathematical formulation implies a line in a 2D field, <span class="math notranslate nohighlight">\(\beta_0\)</span> represents the intercept of the line with the y-axis and <span class="math notranslate nohighlight">\(\beta_1\)</span> represents the slope of the line.</p>
<img src="https://www.dropbox.com/s/g8smbktpeqgl90u/regressionmodel.png?dl=1" alt="regression_model" width="50%" align="center"/><p>Let’s assume that <span class="math notranslate nohighlight">\(\beta_0\)</span> is <span class="math notranslate nohighlight">\(20\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> is <span class="math notranslate nohighlight">\(0.5\)</span>. This would mean that our regression model becomes:</p>
<div class="math notranslate nohighlight">
\[\text{sales} = 20+ 0.5\text{TV}\]</div>
<p>This would mean we could insert X and calculate <span class="math notranslate nohighlight">\(\hat{Y}\)</span>.</p>
<p>For example, if we assume we spent 100 in TV advertisment we would expect sales of</p>
<div class="math notranslate nohighlight">
\[\text{sales} = 20 + 0.5\times100 = 70\]</div>
<p>Spending 100.000 USD in TV advertisment would yield in 70.000 Units of sales according to our model.</p>
<p>(Note: sales and TV spent both in in units of thousands)</p>
<p><strong>How do you determine coefficients?</strong><br />
In our example we have just assumed values for <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span>. In practice we need to determine both coefficients. In order to derive how we do this it is helpful to look at the following interactive example:</p>
<p><a class="reference external" href="https://share.streamlit.io/fredzett/rmqa/regression.py">Interactive example</a></p>
</div>
<div class="section" id="estimation-of-regression-function">
<h2>Estimation of regression function<a class="headerlink" href="#estimation-of-regression-function" title="Permalink to this headline">¶</a></h2>
<div class="section" id="simple-linear-regression">
<h3>Simple linear regression<a class="headerlink" href="#simple-linear-regression" title="Permalink to this headline">¶</a></h3>
<p>We need to find coefficients that specify a line which describes the true relationship as best as possible.</p>
<p>This is achieved by minimizing the <em>least squares</em> criterion, i.e. we want to minimize the resdiual sum of squares (RSS; sometimes SSR)</p>
<div class="math notranslate nohighlight">
\[
\text{RSS} = \sum_{i=1}^n e_i^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(e_i\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
e_i = y_i - \hat{y}_i
\]</div>
<p>The <strong>least squares criterion</strong> avoids that positive and negative deviations cancel each other out and weighs more heavily on large deviations (which may also be a disadvantage if we find to have outlier in our data).</p>
<p>Analytically we can then derive <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span> that minimizes the RSS:</p>
<p>\begin{equation}
\begin{split}
\hat{\beta}<em>1 &amp; = \frac{\sum</em>{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \[10pt]
\hat{\beta}_0 &amp; = \bar{y} - \hat{\beta}_1\bar{x}
\end{split}
\end{equation}</p>
<p>We write <span class="math notranslate nohighlight">\(\hat{\beta}_i\)</span> to indicate that it is an estimator. We omit if this is clear from the context.</p>
<p>We can easily implement the above formulas in python and calculate the correct values for both coefficients</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write functions for b0, b1</span>
<span class="k">def</span> <span class="nf">beta1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="n">________</span> <span class="c1"># insert function</span>

<span class="k">def</span> <span class="nf">beta0</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="n">________</span> <span class="c1"># insert function</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;sales&quot;</span><span class="p">]</span> <span class="c1"># column &quot;sales&quot;</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;TV&quot;</span><span class="p">]</span> <span class="c1"># column &quot;TV&quot;</span>

<span class="c1">#beta0(x,y), beta1(x,y)</span>
</pre></div>
</div>
</div>
</div>
<p>The optimal regression line can therefore be described as:</p>
<div class="math notranslate nohighlight">
\[\text{sales} = 7.03 + 0.048\times\text{TV}\]</div>
<p>meaning that increasing TV spent by 1.000 USD will increase sales units by 48 (remember that both are in units of thoushands)</p>
<p>Looking at our <a class="reference external" href="https://share.streamlit.io/fredzett/rmqa/regression.py">interactive chart</a> we see that the line does not perfectly describe the relationship given most of the data points are not on the line described by the regression model. This is due to the fact that there are other factors influencing <em>sales</em>. We distinguish between two types of factors:</p>
<ol class="simple">
<li><p><strong>systematic factors</strong>, i.e. other explanatory variables (e.g. price, newspaper ad spent, …) which may drive sales but have not been incorporated into the model</p></li>
<li><p><strong>unsystematic factors</strong>, i.e. other factors which cannot be included because they are unknown</p></li>
</ol>
</div>
<div class="section" id="multiple-regression">
<h3>Multiple regression<a class="headerlink" href="#multiple-regression" title="Permalink to this headline">¶</a></h3>
<p>For most research question it is required that we have more than one indepenent variable. If this is the case the regression model has the following form:</p>
<div class="math notranslate nohighlight">
\[\hat{Y} = \beta_0 + \beta_1x_1 + \beta_2x_2 + \ldots + \beta_Jx_J\]</div>
<p><strong>Example:</strong><br />
We could describe the relationship between <em>sales</em> and advertising spent using all three media types, <em>TV</em>, <em>Newspaper</em> and <em>radio</em>. This would then be described as:</p>
<div class="math notranslate nohighlight">
\[\text{sales} = \beta_0 + \beta_1\text{TV} + \beta_2\text{newspaper} + \beta_3\text{radio}\]</div>
<p>In order to solve for <span class="math notranslate nohighlight">\(\beta_j\)</span> we, in principal, follow the same route than in the simple regression case. However, solving the system of equations is somewhat more complex. It involves solving a system of linear equations of the following form:</p>
<div class="math notranslate nohighlight">
\[Y = X\beta + \epsilon\]</div>
<p>where:</p>
<p>\begin{equation}
Y = \begin{pmatrix} y_1 \ y_2 \ \vdots \ y_n \end{pmatrix},
X = \begin{pmatrix} 1 &amp; x_{11} &amp; x_{12} &amp; \ldots &amp; x_{1p} \ 1 &amp; x_{21} &amp; x_{22} &amp; \ldots &amp; x_{2p} \ \vdots &amp; \vdots &amp;  \vdots  &amp; \vdots &amp; \vdots \ 1 &amp; x_{n1} &amp; x_{n2} &amp; \ldots &amp; x_{np} \end{pmatrix},
\beta = \begin{pmatrix} \beta_0 \ \vdots \ \beta_p  \end{pmatrix},
\epsilon = \begin{pmatrix} \epsilon_0 \ \epsilon_1  \ \vdots \ \epsilon_n  \end{pmatrix},
\end{equation}</p>
<p>Without covering the details of the math this equation can be solved as follows:</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta} = (X^TX)^{-1}X^Ty
\]</div>
<p>What is important here is that there exists an analytical solution for the linear regression problem.</p>
<p>The implementation in python is easy yet not intuitive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fit_ols_multiple</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="nd">@X</span><span class="p">)</span><span class="nd">@X</span><span class="o">.</span><span class="n">T</span><span class="nd">@y</span>
</pre></div>
</div>
</div>
</div>
<p>Also note that in the multiple regression part is it necessary to assume one factor to be consisting of <span class="math notranslate nohighlight">\(1\)</span>s in order to calculate <span class="math notranslate nohighlight">\(\beta_0\)</span> (i.e. the intercept)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;TV&quot;</span><span class="p">,</span><span class="s2">&quot;newspaper&quot;</span><span class="p">,</span><span class="s2">&quot;radio&quot;</span><span class="p">]]</span> <span class="c1"># Define X to be all three variables</span>
<span class="n">X</span><span class="p">[</span><span class="s2">&quot;Intercept&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span> <span class="c1"># add a variable consisting of ones</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="n">fit_ols_multiple</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="c1"># calculate coefficients</span>
<span class="n">coefs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sales</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.045765</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.001037</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.188530</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2.938889</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">coefs</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span> <span class="c1"># assign names of X</span>
<span class="n">coefs</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sales</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>TV</th>
      <td>0.045765</td>
    </tr>
    <tr>
      <th>newspaper</th>
      <td>-0.001037</td>
    </tr>
    <tr>
      <th>radio</th>
      <td>0.188530</td>
    </tr>
    <tr>
      <th>Intercept</th>
      <td>2.938889</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>Implementation in python</strong>:<br />
It is tedious and verbose to implement regression from scratch. We will therefore use existing modules to achieve this. In doing so we can also make use of many statistical tests that are calculated on the fly.</p>
<p>We will use:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">patsy.dmatrices</span></code>: this produces X and y based on a model specification (use model <code class="docutils literal notranslate"><span class="pre">patsy</span></code>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">statsmodels.OLS</span></code>: calculates an ordinary least squares regression (use model <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">from</span> <span class="nn">patsy</span> <span class="kn">import</span> <span class="n">dmatrices</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;sales ~ TV + newspaper + radio&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span> <span class="c1"># y = df[&quot;sales&quot;], X = [Intercept, TV, Newspaper, radio]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span> <span class="c1"># define model</span>
<span class="n">ols</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># optimize model, i.e. calculate coefficients</span>
<span class="n">ols</span><span class="o">.</span><span class="n">params</span> <span class="c1"># print regression parameters (i.e. coefficients)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept    2.938889
TV           0.045765
newspaper   -0.001037
radio        0.188530
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>This is very helpful as we can also use the optimized model (i.e. variable <code class="docutils literal notranslate"><span class="pre">ols</span></code>) to print summary statistics for the entire  regression model.</p>
<p>We will use the combination of both modules / functions to make our lives much easier and be able to explore models.</p>
<p><strong>Meaning of regression coefficients:</strong><br />
We have now seen how to calculate the regression coefficients that minimize the residual sum of squares (RSS). Let’s now focus on how to interpret these coefficients:</p>
<p>The coeffiecients give the <strong>marginal effect of change</strong> of an independent variable on the dependent variable. For example, a coefficient of <code class="docutils literal notranslate"><span class="pre">0.18</span></code> for <code class="docutils literal notranslate"><span class="pre">radio</span></code> means that increasing radio spent by a <span class="math notranslate nohighlight">\(1.000\)</span> USD - and keeping all other variables constant - the sales increase by <span class="math notranslate nohighlight">\(180\)</span>.</p>
<p>It is, however, important to understand that the <strong>size of the coefficient does not indicate importance</strong> and should not be interpreted directly. For example, it cannot be concluded from the above estimation that the effect of <em>TV</em> is less than the effect of <em>radio</em> if we do not know the scale of the variables. More specifically, the scales of the variables need to be of the same size to make such a statement valid. In the above case it is actually valid to make such a statement because all independent (i.e. explanatory) variables are measures in ‘000 USD.</p>
<p>For most models, the scale between different independent variables differs, however.</p>
<p>Let’s look at a different dataset containing information about different car models. The dataset has the following variables:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mpg</span></code> = miles per gallon</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cylinders</span></code> = number of cylinders</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">displacement</span></code> = overall volume in the engine as a factor of cylinder circumfrance, depth and total number of cylinders. This metric gives a good proxy for the total amount of power the engine can generate.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">horsepower</span></code> = gross horsepower</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight</span></code> = weight of the car in lbs</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">acceleration</span></code>= time in seconds to 100mph</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">year</span></code> = year model was produced</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">origin</span></code> = region (1=US, 2=Europe, 3=Asia)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code> = name of model</p></li>
</ul>
<p>Just be looking at the descriptions it becomes apparent that the units of each variable are not comparable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cars</span> <span class="o">=</span> <span class="n">Datasets</span><span class="o">.</span><span class="n">cars</span><span class="p">(</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span> <span class="c1"># Load cars dataset</span>
<span class="n">cars</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mpg</th>
      <th>cylinders</th>
      <th>displacement</th>
      <th>horsepower</th>
      <th>weight</th>
      <th>acceleration</th>
      <th>year</th>
      <th>origin</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>18.0</td>
      <td>8</td>
      <td>307.0</td>
      <td>130</td>
      <td>3504</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>chevrolet chevelle malibu</td>
    </tr>
    <tr>
      <th>1</th>
      <td>15.0</td>
      <td>8</td>
      <td>350.0</td>
      <td>165</td>
      <td>3693</td>
      <td>11.5</td>
      <td>70</td>
      <td>1</td>
      <td>buick skylark 320</td>
    </tr>
    <tr>
      <th>2</th>
      <td>18.0</td>
      <td>8</td>
      <td>318.0</td>
      <td>150</td>
      <td>3436</td>
      <td>11.0</td>
      <td>70</td>
      <td>1</td>
      <td>plymouth satellite</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16.0</td>
      <td>8</td>
      <td>304.0</td>
      <td>150</td>
      <td>3433</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>amc rebel sst</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.0</td>
      <td>8</td>
      <td>302.0</td>
      <td>140</td>
      <td>3449</td>
      <td>10.5</td>
      <td>70</td>
      <td>1</td>
      <td>ford torino</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now let’s assume we want to understand the drivers for <code class="docutils literal notranslate"><span class="pre">mpg</span></code>, i.e. what are factors influencing mileage per gallon. We hypothesize about a model that looks as follows:</p>
<div class="math notranslate nohighlight">
\[\text{mpg} = \beta_0 + \beta_1\text{horsepower} + \beta_2\text{weight} + \beta_3\text{year}\]</div>
<p>Intuitively we would assume that <code class="docutils literal notranslate"><span class="pre">mpg</span></code>:</p>
<ul class="simple">
<li><p>decreases with more <code class="docutils literal notranslate"><span class="pre">horsepower</span></code> and <code class="docutils literal notranslate"><span class="pre">weight</span></code> (as big and/or heavy cars usually are less efficient)</p></li>
<li><p>increases with <code class="docutils literal notranslate"><span class="pre">year</span></code> (as newer cars are more efficient)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;mpg ~ horsepower + weight + year&quot;</span><span class="p">,</span> <span class="n">cars</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span> <span class="c1"># define y and X (including intercept)</span>
<span class="n">ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># optimize model</span>
<span class="n">ols</span><span class="o">.</span><span class="n">params</span> <span class="c1"># print parameters</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept    -13.719360
horsepower    -0.005000
weight        -0.006448
year           0.748705
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Our initial intuition was confirmed given the negative signs of coefficients for <code class="docutils literal notranslate"><span class="pre">horsepower</span></code> and <code class="docutils literal notranslate"><span class="pre">weight</span></code> and the positive coefficient for <code class="docutils literal notranslate"><span class="pre">year</span></code>.</p>
<p>We can now make a statement that <span class="math notranslate nohighlight">\(100\)</span> horsepower extra decreases mileage per gallon by <span class="math notranslate nohighlight">\(5\)</span>.</p>
<p>We may, however, be interested in the <strong>most influential factor</strong>. What is driving <code class="docutils literal notranslate"><span class="pre">mpg</span></code> the most? In this example we cannot state that <code class="docutils literal notranslate"><span class="pre">year</span></code> is driving horsepower the most given the units and scales of all three variables are not comparable.</p>
<p><strong>Standardized coefficients</strong><br />
In order to answer the question with of the <span class="math notranslate nohighlight">\(X\)</span>s is most important for determining <span class="math notranslate nohighlight">\(Y\)</span> we need to make our <span class="math notranslate nohighlight">\(\beta\)</span>s comparable. We can do this following two ways:</p>
<ol class="simple">
<li><p>Standardize variables using <em>z score</em></p></li>
<li><p>Standardize coefficients</p></li>
</ol>
<p><strong>Z-Score approach</strong></p>
<ul class="simple">
<li><p>standardize the variables using a z-score (i.e. mean of 0 and standard deviation of 1 for each variable)</p></li>
<li><p>run ols regression and receive standardized coefficients</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;mpg ~ horsepower + weight + year&quot;</span><span class="p">,</span> <span class="n">cars</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span> <span class="c1"># define y and X (including intercept)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">zscore</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;horsepower&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;year&quot;</span><span class="p">]:</span>
    <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># optimize model</span>
<span class="n">ols</span><span class="o">.</span><span class="n">params</span> <span class="c1"># print parameters</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept    -3.096481e-16
horsepower   -2.465684e-02
weight       -7.016947e-01
year          3.533670e-01
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Notice that the optimal parameters have changed. We can now compare the coefficients and say that</p>
<ul class="simple">
<li><p>horsepower has the least impact</p></li>
<li><p>year has the second least impact</p></li>
<li><p>weight has the most impact and it’s impact is 2x as high as the impact for year</p></li>
</ul>
<p>It is recommended to use the below approach as it avoids</p>
<ul class="simple">
<li><p>rerunning the entire model with new variables</p></li>
<li><p>leaves <span class="math notranslate nohighlight">\(X\)</span>s unchanged</p></li>
</ul>
<p><strong>Standardized coefficients approach</strong></p>
<ul class="simple">
<li><p>run ols regression using nominal (i.e. original) values for variables</p></li>
<li><p>convert nominal coefficients using $<span class="math notranslate nohighlight">\(\beta_{j,std} = \beta_j \cdot \frac{s_{X_j}}{s_Y}\)</span>$</p></li>
</ul>
<p>where</p>
<p><span class="math notranslate nohighlight">\(\beta_{j,std}\)</span> = standardized coefficient for variable <span class="math notranslate nohighlight">\(X_j\)</span><br />
<span class="math notranslate nohighlight">\(\beta_j\)</span> = unstandardized / nominal coefficient for variable <span class="math notranslate nohighlight">\(X_j\)</span><br />
<span class="math notranslate nohighlight">\(s_{X_j}\)</span> = standard deviation of <span class="math notranslate nohighlight">\(X_j\)</span><br />
<span class="math notranslate nohighlight">\(s_Y\)</span> = standard deviation of <span class="math notranslate nohighlight">\(Y\)</span></p>
<p>Let’s do this in python</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;mpg ~ horsepower + weight + year&quot;</span><span class="p">,</span> <span class="n">cars</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span> <span class="c1"># define y and X (including intercept)</span>
<span class="n">ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># optimize model</span>
<span class="n">ols</span><span class="o">.</span><span class="n">params</span> <span class="c1"># print parameters</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept    -13.719360
horsepower    -0.005000
weight        -0.006448
year           0.748705
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ols</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="p">[</span><span class="s2">&quot;horsepower&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">,</span> <span class="s2">&quot;year&quot;</span><span class="p">]):</span>
    <span class="n">bstd</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">])</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">bstd</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[-0.02465684]
[-0.70169467]
[0.35336703]
</pre></div>
</div>
</div>
</div>
<p>We can see that the resulting coefficients are different from the z-score approach. However, the interpretation yields exactly the same conclusion:</p>
<ul class="simple">
<li><p>horsepower has the least impact</p></li>
<li><p>year has the second least impact</p></li>
<li><p>weight has the most impact and it’s impact is 2x as high as the impact for year</p></li>
</ul>
<p><strong>Interpretation of standardized coefficients</strong><br />
We can say that changing <span class="math notranslate nohighlight">\(X_j\)</span> bei <span class="math notranslate nohighlight">\(1\)</span> standard deviation changes <span class="math notranslate nohighlight">\(Y\)</span> bei <span class="math notranslate nohighlight">\(\beta_{j, std}\)</span> standard deviations.</p>
<p>Example: changing <code class="docutils literal notranslate"><span class="pre">year</span></code> by <span class="math notranslate nohighlight">\(1\)</span> standard deviation changes <code class="docutils literal notranslate"><span class="pre">mpg</span></code> by <span class="math notranslate nohighlight">\(0.35\ldots\)</span> standard deviations. This means</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bjstd</span> <span class="o">=</span> <span class="mf">0.35336703</span>
<span class="n">std_mpg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">std_mpg</span> <span class="o">*</span> <span class="n">bjstd</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mpg    2.754512
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>We can confirm this is true by comparing to the original parameter</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bj</span> <span class="o">=</span> <span class="mf">0.748705</span>
<span class="n">std_year</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="s2">&quot;year&quot;</span><span class="p">])</span>
<span class="n">std_year</span><span class="o">*</span><span class="n">bj</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.7545118245163795
</pre></div>
</div>
</div>
</div>
<p>Summarizing:</p>
<ul class="simple">
<li><p>nominal coefficients: use to show “real unit” effect of <span class="math notranslate nohighlight">\(X\)</span> on <span class="math notranslate nohighlight">\(y\)</span></p></li>
<li><p>standardized coefficients: use to compare effect size of <span class="math notranslate nohighlight">\(X\)</span>s on <span class="math notranslate nohighlight">\(y\)</span></p></li>
</ul>
</div>
</div>
<div class="section" id="evaluation-of-regression-function">
<h2>Evaluation of regression function<a class="headerlink" href="#evaluation-of-regression-function" title="Permalink to this headline">¶</a></h2>
<p>We have esimtated our regression function. However, we don’t know how good the model. We have used a model to approximate reality and we need to understand how good our model is in doing so. We therefore need to evaluate our model. This consists of two types of evaluation:</p>
<ol class="simple">
<li><p><strong>Global assessment</strong>, i.e. how good can <span class="math notranslate nohighlight">\(Y\)</span> be explained by <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p><strong>Coefficient assemssment</strong>, i.e. if and how individual <span class="math notranslate nohighlight">\(X\)</span>s contribute to explaining <span class="math notranslate nohighlight">\(Y\)</span></p></li>
</ol>
<div class="section" id="global-assessment-of-regression-model">
<h3>Global assessment of regression model<a class="headerlink" href="#global-assessment-of-regression-model" title="Permalink to this headline">¶</a></h3>
<p>The global assessment, i.e. the goodness of fit, can be done using two different metrics:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(R^2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(F\)</span>-Statistic</p></li>
</ol>
<p>We have seen that we optimize our regression model by minimizing</p>
<div class="math notranslate nohighlight">
\[
\text{RSS} = \sum_{i=1}^n e_i^2
\]</div>
<p>Unfortunately, we cannot use RSS as an indicator of how good our model is as it is dependents on the size of the dataset. The larger the dataset the higher the RSS.</p>
<p>However, we can disassemble the RSS in</p>
<ul class="simple">
<li><p>explained deviation and</p></li>
<li><p>unexplained deviation</p></li>
</ul>
<p>Let’s look at the deviations in the simple linear regression case with one explanatory variable <span class="math notranslate nohighlight">\(X\)</span> and the dependent variable <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<img src="https://www.dropbox.com/s/rz386z8fvl43o6o/regression_deviation.png?dl=1" alt="regression_model" width="50%" align="center"/>
<p>Let’s analyse one single observation <span class="math notranslate nohighlight">\(x_i\)</span> with its corresponding observation <span class="math notranslate nohighlight">\(y_i\)</span>. The point <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> is above the mean <span class="math notranslate nohighlight">\(\bar{y}\)</span>. We treat <span class="math notranslate nohighlight">\(y_i - \bar{y}\)</span> as the total deviation. This deviation can be separated into:</p>
<ul class="simple">
<li><p>explained deviation: <span class="math notranslate nohighlight">\(\hat{y}_i - \bar{y}\)</span>; given <span class="math notranslate nohighlight">\(x_i\)</span> is higher than <span class="math notranslate nohighlight">\(\bar{x}\)</span> we expect <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> to be higher than <span class="math notranslate nohighlight">\(\bar{y}\)</span></p></li>
<li><p>unexplained deviation: <span class="math notranslate nohighlight">\(\epsilon_i\)</span>; cannot be exlained by the above argument</p></li>
</ul>
<p>We can therefore say that: <em>total deviation = explained deviation + residuum</em></p>
<p>Which can trivially be written as:</p>
<div class="math notranslate nohighlight">
\[y_i - \bar{y} = (\hat{y}_i - \bar{y}) + (y_i - \hat{y}_i)\]</div>
<p>This equation also holds for multiple regressions.</p>
<p><strong>Definition of <span class="math notranslate nohighlight">\(R^2\)</span></strong><br />
Is derived from this relationship and is defined as</p>
<div class="math notranslate nohighlight">
\[R^2 = \frac{\text{explained deviation}}{\text{total deviation}} = \frac{\sum_{i=1}^I (\hat{y}_i - \bar{y})^2}{\sum_{i=1}^I (y_i - \bar{y})^2}\]</div>
<p>The <span class="math notranslate nohighlight">\(R^2\)</span> score can be interpreted as how much % can be explained by the specified model. (Note: altenatively, the <span class="math notranslate nohighlight">\(R^2\)</span> can also be calculated as the square of the correlation between <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(\hat{Y}\)</span>).</p>
<p>Let’s look at our original advertisment model and see how good the model actually is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;sales ~ TV&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span> <span class="c1"># y = df[&quot;sales&quot;], X = [Intercept, TV]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span> <span class="c1"># define model</span>
<span class="n">ols</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span> <span class="c1"># optimize model, i.e. calculate coefficients</span>
<span class="n">ols</span><span class="o">.</span><span class="n">rsquared</span> <span class="c1"># print regression parameters (i.e. coefficients)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.611875050850071
</pre></div>
</div>
</div>
</div>
<p>Alternatively we can calcualte it as the square of correlation between <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(\hat{Y}\)</span>,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat</span> <span class="o">=</span> <span class="n">ols</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">y</span><span class="p">,</span><span class="n">yhat</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ys</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sales</th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>sales</th>
      <td>1.000000</td>
      <td>0.611875</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.611875</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Either way, this means that <span class="math notranslate nohighlight">\(\approx 60\%\)</span> of sales deviation can be explained by spent in TV advertisment.</p>
<p>While the <span class="math notranslate nohighlight">\(R^2\)</span> is a good metric it has some drawbacks, mostly:</p>
<ul class="simple">
<li><p>does not account for size of dataset: for example the <span class="math notranslate nohighlight">\(R^2\)</span> of two data points is always 1 given we can always connect them using a line</p></li>
<li><p>does not account for number of <span class="math notranslate nohighlight">\(X\)</span>s: complex models with many variables always have a higher <span class="math notranslate nohighlight">\(R^2\)</span> (all other things being equal)</p></li>
</ul>
<p>To compensate for these drawbacks we can use</p>
<ul class="simple">
<li><p>adjusted <span class="math notranslate nohighlight">\(R^2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(F\)</span>-statistic</p></li>
</ul>
<p><strong>Adjusted <span class="math notranslate nohighlight">\(R^2\)</span></strong><br />
Takes the number of variables into account and adjusts for it by</p>
<div class="math notranslate nohighlight">
\[R^2_{adj} = R^2 - \frac{J \cdot (1 - R^2}{N- J - 1}\]</div>
<p>where:</p>
<p><span class="math notranslate nohighlight">\(N\)</span> = number of observations (i.e. elements in dataset)<br />
<span class="math notranslate nohighlight">\(J\)</span> = number of coefficients (i.e. variables in datatset)<br />
<span class="math notranslate nohighlight">\(N - J - 1\)</span> = number of degrees of freedom</p>
<p>Comparison of <span class="math notranslate nohighlight">\(R^2\)</span> and <span class="math notranslate nohighlight">\(R^2_{adj}\)</span> using our advertisment dataset</p>
<p><strong>F-Statistic</strong></p>
<p>The <span class="math notranslate nohighlight">\(R^2\)</span> measures how much of <span class="math notranslate nohighlight">\(Y\)</span> can be explained by the model. Given in most research (and practical) context our data is based on a sample and not a population we have to understand to what extend the model - based on the sample data - is valid for the population. Therefore, we need to <strong>understand the statistical significance of the model</strong>. This is what the <span class="math notranslate nohighlight">\(F\)</span>-statistic is used for.</p>
<p>The <span class="math notranslate nohighlight">\(F\)</span>-statistic includes</p>
<ul class="simple">
<li><p>the deviations explained above</p></li>
<li><p>the number of observations</p></li>
<li><p>the number of coefficients</p></li>
</ul>
<p>Given the estimated regression function (of a sample)</p>
<div class="math notranslate nohighlight">
\[\hat{Y} = \beta_0 + \beta_1x_1 + \beta_2x_2 + \ldots + \beta_Jx_J + \epsilon\]</div>
<p>can be interpreted as “true” function with unknown parameters <span class="math notranslate nohighlight">\(\beta_0, \beta_1, \beta_2, \ldots,\beta_J\)</span> which describes the causal realtionship of the population. This function includes an error term (<span class="math notranslate nohighlight">\(\epsilon\)</span>). Therefore, the regression function can be regarded as a <strong>stochastic model</strong>.</p>
<p>As discussed <span class="math notranslate nohighlight">\(\epsilon\)</span> includes all random factors which drive the dependent variable <span class="math notranslate nohighlight">\(Y\)</span>. This variable cannot be observed directly (given we don’t know which unsystematic factors influence <span class="math notranslate nohighlight">\(Y\)</span> or else we would have included them) but is measured by the <strong>residuals</strong>.</p>
<p>It follows from the above statement that <span class="math notranslate nohighlight">\(Y\)</span> is also a random variable and the the coefficients (i.e. <span class="math notranslate nohighlight">\(\beta\)</span>s) are also realisation of random variables. Therefore with different samples these coefficients will vary around the true value of <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<p>If a causal relationship exists betwenn <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X\)</span> then the true regression coefficients must be different from zero.</p>
<p>To this end, for testing the significance of the regression model the following <strong>null hypotheses must be tested</strong>:</p>
<div class="math notranslate nohighlight">
\[H_0 : \beta_0 = \beta_1 = \ldots = \beta_J = 0\]</div>
<p>For testing this hypothesis we conduct the <span class="math notranslate nohighlight">\(F\)</span>-Test using the <span class="math notranslate nohighlight">\(F\)</span>-distribution doing the following:</p>
<ul class="simple">
<li><p>calculate the empirical <span class="math notranslate nohighlight">\(F\)</span>-value from the model</p></li>
<li><p>provide significance level</p></li>
<li><p>compare to the theoretical <span class="math notranslate nohighlight">\(F\)</span>-value given the <span class="math notranslate nohighlight">\(F\)</span>-distribution / calculate p-values</p></li>
</ul>
<p><strong>Calculation of empirical <span class="math notranslate nohighlight">\(F\)</span>-value</strong>:</p>
<div class="math notranslate nohighlight">
\[F_emp = \frac{\sum_{i=1}^I(\hat{y}_i - \bar{y})^2/J}{\sum_{i=1}^I(y_i - \hat{y}_i)^2/(I - J - 1)} = \frac{\text{explained deviation}/J}{\text{unexplained deviation}/(I - J - 1)} = \frac{R^2/J}{(1 - R^2)/(I - J - 1)}\]</div>
<p>where:</p>
<p><span class="math notranslate nohighlight">\(I\)</span> = number of observations<br />
<span class="math notranslate nohighlight">\(J\)</span> = number of parameters (coefficients)</p>
<p>Example using the <code class="docutils literal notranslate"><span class="pre">car</span> <span class="pre">dataset</span></code></p>
<p><strong>1. calcualte empirical f-value</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Caluclate model</span>
<span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;mpg ~ horsepower + weight + year&quot;</span><span class="p">,</span> <span class="n">cars</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span> 
<span class="n">ols</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">f_emp</span> <span class="o">=</span> <span class="n">ols</span><span class="o">.</span><span class="n">fvalue</span>
<span class="n">f_emp</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>545.3985163061409
</pre></div>
</div>
</div>
</div>
<p>We can use the function from our model. However, let’s check if the value can actually be recalculated using the above formula:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fvalue</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> 
    <span class="n">yhat</span> <span class="o">=</span> <span class="n">ols</span><span class="o">.</span><span class="n">fittedvalues</span>
    <span class="n">ybar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">yhat</span><span class="p">)</span>
    <span class="n">J</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span> <span class="c1"># exclude intercept</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">fvalue</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">yhat</span> <span class="o">-</span> <span class="n">ybar</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">J</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">I</span><span class="o">-</span><span class="n">J</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">fvalue</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate empirical F-value</span>
<span class="n">fvalue</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>545.3985163061416
</pre></div>
</div>
</div>
</div>
<p>We will use the function from statsmodels from now on.</p>
<p><strong>2. determine significance level</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
</pre></div>
</div>
</div>
</div>
<p><strong>3. compare to theoretical f-value</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfj</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> <span class="c1"># three independent variables</span>
<span class="n">dfn</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">-</span> <span class="n">dfj</span> <span class="o">-</span> <span class="mi">1</span> <span class="c1"># degrees of freedom</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">dfj</span><span class="p">,</span> <span class="n">dfn</span><span class="p">)</span>
<span class="n">pvalue</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">f</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">f_emp</span><span class="p">)</span>
<span class="k">if</span> <span class="n">pvalue</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Null hypothesis can be rejected&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span> 
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Null hypothesis cannot be rejected&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Null hypothesis can be rejected
</pre></div>
</div>
</div>
</div>
<p>Interpretation: our model yields an empirical <span class="math notranslate nohighlight">\(F\)</span>-value that is very unlikely under the theoretical <span class="math notranslate nohighlight">\(F\)</span>-distribuation. Therefore, we can conclude that at least one of the parameters (<span class="math notranslate nohighlight">\(\beta\)</span>s) is not equal to zero. This means that we actually can be quite certain that we have specified a model that found a (statistical) realtion between <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X\)</span>.</p>
</div>
<div class="section" id="assessment-of-regression-coefficients">
<h3>Assessment of regression coefficients<a class="headerlink" href="#assessment-of-regression-coefficients" title="Permalink to this headline">¶</a></h3>
<p>We have so far “only” tested the significance of the entire model. However, we have not tested the individual coefficients.</p>
<p>The common hypothesis we need to evaluate is:</p>
<div class="math notranslate nohighlight">
\[H_0 : \beta_j = 0\]</div>
<p>(note that we could in principal also conduct other hypotheses)</p>
<p><strong><span class="math notranslate nohighlight">\(t\)</span>-statistic</strong></p>
<p>We have seen in previous chapter how to conduct the <span class="math notranslate nohighlight">\(t\)</span>-test. The steps are the same as with the <span class="math notranslate nohighlight">\(F\)</span>-test.</p>
<ol class="simple">
<li><p>we calculate the emprical <span class="math notranslate nohighlight">\(t\)</span>-value</p></li>
<li><p>we provide significance level</p></li>
<li><p>we compare to the theoretical <span class="math notranslate nohighlight">\(t\)</span>-value given the <span class="math notranslate nohighlight">\(t\)</span>-distribution / calculate p-values</p></li>
</ol>
<p>If we test the null hypothesis as described above the emprical <span class="math notranslate nohighlight">\(t\)</span>-value can be determined using:</p>
<div class="math notranslate nohighlight">
\[t_\text{emp} = \frac{\beta_j}{s_{\beta_j}}\]</div>
<p>where:</p>
<p><span class="math notranslate nohighlight">\(s_{\beta_j}\)</span> = the standard error of <span class="math notranslate nohighlight">\(\beta_j\)</span>.</p>
<p>The calculation of the standard error in the multiple regression case is somewhat more complex and will not be covered here. This is due to the fact that</p>
<ol class="simple">
<li><p>most statistical packages yield the standard errors</p></li>
<li><p>we could calculate it using a bootstrap approach</p></li>
</ol>
<p>For further information on the calculation of standard errors see, e.g., <a class="reference external" href="https://www.springer.com/de/book/9783662460764"><em>Backhaus et al (2017), p. 122ff</em></a>.</p>
<p>Example: using the above model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t_emp</span> <span class="o">=</span> <span class="n">ols</span><span class="o">.</span><span class="n">tvalues</span>
<span class="n">t_emp</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept     -3.280764
horsepower    -0.529690
weight       -15.767548
year          14.365022
dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">pvalues</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">dfn</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">t_emp</span><span class="p">))</span>
<span class="k">for</span> <span class="n">pvalue</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pvalues</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">pvalue</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Null hypothesis for </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2"> can be rejected&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> 
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Null hypothesis for </span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2"> cannot be rejected&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Null hypothesis for Intercept can be rejected
Null hypothesis for horsepower cannot be rejected
Null hypothesis for weight can be rejected
Null hypothesis for year can be rejected
</pre></div>
</div>
</div>
</div>
<p><strong>Confidence intervals using bootstrap approach</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sims</span> <span class="o">=</span> <span class="mi">10_000</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">sims</span><span class="p">,</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sims</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)),</span><span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
    <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx</span><span class="p">,:])</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">params</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.025</span><span class="p">,</span><span class="mf">0.975</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept [-21.37340957  -6.05244358]
horsepower [-0.02480722  0.01476044]
weight [-0.00730325 -0.00564262]
year [0.65134201 0.84715418]
</pre></div>
</div>
</div>
</div>
<p>Using the <code class="docutils literal notranslate"><span class="pre">summary</span></code> function we can, however, make this analysis less verbose. We also get other statistics such as</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ols</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.808</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.807</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   545.4</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>9.37e-139</td>
</tr>
<tr>
  <th>Time:</th>                 <td>20:58:38</td>     <th>  Log-Likelihood:    </th> <td> -1037.4</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2083.</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   388</td>      <th>  BIC:               </th> <td>   2099.</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>  <td>  -13.7194</td> <td>    4.182</td> <td>   -3.281</td> <td> 0.001</td> <td>  -21.941</td> <td>   -5.498</td>
</tr>
<tr>
  <th>horsepower</th> <td>   -0.0050</td> <td>    0.009</td> <td>   -0.530</td> <td> 0.597</td> <td>   -0.024</td> <td>    0.014</td>
</tr>
<tr>
  <th>weight</th>     <td>   -0.0064</td> <td>    0.000</td> <td>  -15.768</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.006</td>
</tr>
<tr>
  <th>year</th>       <td>    0.7487</td> <td>    0.052</td> <td>   14.365</td> <td> 0.000</td> <td>    0.646</td> <td>    0.851</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>41.952</td> <th>  Durbin-Watson:     </th> <td>   1.227</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  69.490</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.671</td> <th>  Prob(JB):          </th> <td>8.14e-16</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.566</td> <th>  Cond. No.          </th> <td>7.48e+04</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.48e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</div></div>
</div>
</div>
</div>
<div class="section" id="validating-model-assumptions">
<h2>Validating model assumptions<a class="headerlink" href="#validating-model-assumptions" title="Permalink to this headline">¶</a></h2>
<p>We have so far not discussed the assumptions that we depend on when calculating test statistics etc. For calculating these statistics we mainly rely on the residual which is stochastic. We introduced this term to incorporate uncertainty into our model which must be included given that we are estimating a model (and its parameters) based on a sample (see last chapter). When conducting the regression analysis we make multiple assumptions regarding the stochastic component.</p>
<p><strong>Assumptions</strong>:</p>
<ol class="simple">
<li><p>the model is correctly specified</p>
<ul class="simple">
<li><p>it is linear for the parameters (<span class="math notranslate nohighlight">\(\beta\)</span>s)</p></li>
<li><p>it includes the relevant explanatory variables</p></li>
<li><p>the number of estimated parameters (J + 1) is smaller than the number of observations (I)</p></li>
</ul>
</li>
<li><p>the expected value of <span class="math notranslate nohighlight">\(\epsilon\)</span> is zero</p></li>
<li><p>the correlation between the explanatory variables and <span class="math notranslate nohighlight">\(\epsilon\)</span> is zero</p></li>
<li><p>the variance of <span class="math notranslate nohighlight">\(\epsilon\)</span> is constant (called <em>homoscedasticity</em>)</p></li>
<li><p>there is no autocorrelation in <span class="math notranslate nohighlight">\(\epsilon\)</span></p></li>
<li><p>there is no linear dependency between the explanatory variables <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p>the residuals are normally distributed</p></li>
</ol>
<p>If assumptions 1 to 6 hold the linear regression model yields unbiased estimates (best linear unbiased estimator, BLUE).</p>
<p>For conducting the significance tests (<span class="math notranslate nohighlight">\(F\)</span>- and <span class="math notranslate nohighlight">\(t\)</span>-test) assumption 7 needs to hold.</p>
<p>Please refer to [<em>Backhaus et al (2017), p. 89ff</em>] for furter details on testing model assumptions.</p>
</div>
<div class="section" id="non-linearity">
<h2>Non-linearity<a class="headerlink" href="#non-linearity" title="Permalink to this headline">¶</a></h2>
<p>A common misconception with linear regression is that the relation between <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(X\)</span> needs to be linear. This is actually not the case. Assumption A1 only stipulates for linearity in the parameters. It is possible in many cases to transform non-linear relationships into linear relationships.</p>
<p>Given the model</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_1X + \epsilon\]</div>
<p>we can replace <span class="math notranslate nohighlight">\(X\)</span> with <span class="math notranslate nohighlight">\(X' = f(X)\)</span>, where <span class="math notranslate nohighlight">\(f\)</span> is a nonlinear function. The resulting model:</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_1X' + \epsilon\]</div>
<p>is still linear in its parameters.</p>
<p>The most common nonlinear transformations in using linear regression is the log-transformation.</p>
<p>Remember that $<span class="math notranslate nohighlight">\(log(a) = b \leftrightarrow a = e^b\)</span>$</p>
<p>We can distinguish between four model types:</p>
<ol class="simple">
<li><p>level-level model: <span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1X + \epsilon\)</span></p></li>
<li><p>log-level model: <span class="math notranslate nohighlight">\(log_e(y) = \beta_0 + \beta_1X + \epsilon\)</span></p></li>
<li><p>level-log model: <span class="math notranslate nohighlight">\(Y = \beta_0 + \beta_1log_e(X) + \epsilon\)</span></p></li>
<li><p>log-log model: <span class="math notranslate nohighlight">\(log_e(y) = \beta_0 + \beta_1log_e(X) + \epsilon\)</span></p></li>
</ol>
<p>When using models 2 to 4 it is important that the interpretation of the coefficients differs from the <em>level-level</em> model. Interpretations are as follows:</p>
<ul class="simple">
<li><p>log-level: increasing <span class="math notranslate nohighlight">\(X\)</span> by one unit changes <span class="math notranslate nohighlight">\(Y\)</span>(on average and approximately) by <span class="math notranslate nohighlight">\(100 \cdot \beta_1\%\)</span></p></li>
<li><p>level-log: increasing <span class="math notranslate nohighlight">\(X\)</span> by one percent, changes <span class="math notranslate nohighlight">\(Y\)</span> (on average) by <span class="math notranslate nohighlight">\(\beta_1/100\)</span> units</p></li>
<li><p>log-log: increasing <span class="math notranslate nohighlight">\(X\)</span> by one percent, changes <span class="math notranslate nohighlight">\(Y\)</span> (on average) by <span class="math notranslate nohighlight">\(\beta_1\%\)</span></p></li>
</ul>
<p>In order to determine if it is helpful to transform data we should <strong>inspect it visually</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cars</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mpg</th>
      <th>cylinders</th>
      <th>displacement</th>
      <th>horsepower</th>
      <th>weight</th>
      <th>acceleration</th>
      <th>year</th>
      <th>origin</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>18.0</td>
      <td>8</td>
      <td>307.0</td>
      <td>130</td>
      <td>3504</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>chevrolet chevelle malibu</td>
    </tr>
    <tr>
      <th>1</th>
      <td>15.0</td>
      <td>8</td>
      <td>350.0</td>
      <td>165</td>
      <td>3693</td>
      <td>11.5</td>
      <td>70</td>
      <td>1</td>
      <td>buick skylark 320</td>
    </tr>
    <tr>
      <th>2</th>
      <td>18.0</td>
      <td>8</td>
      <td>318.0</td>
      <td>150</td>
      <td>3436</td>
      <td>11.0</td>
      <td>70</td>
      <td>1</td>
      <td>plymouth satellite</td>
    </tr>
    <tr>
      <th>3</th>
      <td>16.0</td>
      <td>8</td>
      <td>304.0</td>
      <td>150</td>
      <td>3433</td>
      <td>12.0</td>
      <td>70</td>
      <td>1</td>
      <td>amc rebel sst</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.0</td>
      <td>8</td>
      <td>302.0</td>
      <td>140</td>
      <td>3449</td>
      <td>10.5</td>
      <td>70</td>
      <td>1</td>
      <td>ford torino</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">cars</span><span class="p">[[</span><span class="s2">&quot;mpg&quot;</span><span class="p">,</span> <span class="s2">&quot;horsepower&quot;</span><span class="p">,</span><span class="s2">&quot;acceleration&quot;</span><span class="p">,</span> <span class="s2">&quot;origin&quot;</span> <span class="p">]]</span> <span class="c1"># let&#39;s take four variables and inspect them</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s2">&quot;origin&quot;</span><span class="p">);</span> <span class="c1"># show pair by pair plot for all variables, color indicates origin</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/S05a_Regression_96_0.png" src="../../_images/S05a_Regression_96_0.png" />
</div>
</div>
<p>We can see that <code class="docutils literal notranslate"><span class="pre">mpg</span></code> and <code class="docutils literal notranslate"><span class="pre">horsepower</span></code> seems to be non-linear.</p>
<p>We could therefore decide (and test) to transform one or both of the variables.</p>
<p>Let’s see how that works.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;mpg&quot;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;horsepower&quot;</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span> <span class="o">=</span> <span class="n">axes</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),</span> <span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;mpg vs. horsepower&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span> <span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;log(mpg) vs. log(horsepower)&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/S05a_Regression_98_0.png" src="../../_images/S05a_Regression_98_0.png" />
</div>
</div>
<p>Let’s run a regression analysis on both models</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;mpg ~ horsepower&quot;</span><span class="p">,</span> <span class="n">cars</span><span class="p">)</span>
<span class="n">ols1</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">ols1</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.606</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.605</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   599.7</td>
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>7.03e-81</td>
</tr>
<tr>
  <th>Time:</th>                 <td>22:11:49</td>     <th>  Log-Likelihood:    </th> <td> -1178.7</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2361.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>   2369.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>  <td>   39.9359</td> <td>    0.717</td> <td>   55.660</td> <td> 0.000</td> <td>   38.525</td> <td>   41.347</td>
</tr>
<tr>
  <th>horsepower</th> <td>   -0.1578</td> <td>    0.006</td> <td>  -24.489</td> <td> 0.000</td> <td>   -0.171</td> <td>   -0.145</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>16.432</td> <th>  Durbin-Watson:     </th> <td>   0.920</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  17.305</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.492</td> <th>  Prob(JB):          </th> <td>0.000175</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.299</td> <th>  Cond. No.          </th> <td>    322.</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat</span> <span class="o">=</span> <span class="n">ols1</span><span class="o">.</span><span class="n">fittedvalues</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">yhat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/S05a_Regression_101_0.png" src="../../_images/S05a_Regression_101_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;np.log(mpg) ~ np.log(horsepower)&quot;</span><span class="p">,</span> <span class="n">cars</span><span class="p">)</span>
<span class="n">ols2</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">ols2</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>np.log(mpg)</td>   <th>  R-squared:         </th> <td>   0.723</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.722</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1016.</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>1.13e-110</td>
</tr>
<tr>
  <th>Time:</th>                 <td>22:46:35</td>     <th>  Log-Likelihood:    </th> <td>  118.52</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>  -233.0</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>  -225.1</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>          <td>    6.9606</td> <td>    0.121</td> <td>   57.296</td> <td> 0.000</td> <td>    6.722</td> <td>    7.199</td>
</tr>
<tr>
  <th>np.log(horsepower)</th> <td>   -0.8418</td> <td>    0.026</td> <td>  -31.881</td> <td> 0.000</td> <td>   -0.894</td> <td>   -0.790</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 6.244</td> <th>  Durbin-Watson:     </th> <td>   1.094</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.044</td> <th>  Jarque-Bera (JB):  </th> <td>   8.144</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.122</td> <th>  Prob(JB):          </th> <td>  0.0170</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.663</td> <th>  Cond. No.          </th> <td>    64.6</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat</span> <span class="o">=</span> <span class="n">ols2</span><span class="o">.</span><span class="n">fittedvalues</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">yhat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/S05a_Regression_103_0.png" src="../../_images/S05a_Regression_103_0.png" />
</div>
</div>
<p>Just looking at the two graphs we can see that the second model (log-log) seems to be better and capturing / explaining the deviation. We can also confirm this when looking at the <span class="math notranslate nohighlight">\(R^2\)</span> value which is <span class="math notranslate nohighlight">\(72\)</span>% vs. <span class="math notranslate nohighlight">\(61\)</span>%.</p>
</div>
<div class="section" id="interaction-effects">
<h2>Interaction effects<a class="headerlink" href="#interaction-effects" title="Permalink to this headline">¶</a></h2>
<p>A special case of non-linearity occurs when we combine two or more variables multiplicatively. This may be necessary or feasible if one effect depends (or is conditional) on another effect.</p>
<p>Let’s return to our <code class="docutils literal notranslate"><span class="pre">advertisment</span></code> data set where we analyzed the causal relationship between <code class="docutils literal notranslate"><span class="pre">sales</span></code> and advertisment spent on <code class="docutils literal notranslate"><span class="pre">TV</span></code>,  <code class="docutils literal notranslate"><span class="pre">newspaper</span></code> and <code class="docutils literal notranslate"><span class="pre">radio</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">Datasets</span><span class="o">.</span><span class="n">advertising</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;pandas&quot;</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
<span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;sales ~ TV  + radio&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
<span class="n">sales_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">sales_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared:         </th> <td>   0.897</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   859.6</td>
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>4.83e-98</td>
</tr>
<tr>
  <th>Time:</th>                 <td>22:46:42</td>     <th>  Log-Likelihood:    </th> <td> -386.20</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   778.4</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   197</td>      <th>  BIC:               </th> <td>   788.3</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    2.9211</td> <td>    0.294</td> <td>    9.919</td> <td> 0.000</td> <td>    2.340</td> <td>    3.502</td>
</tr>
<tr>
  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.909</td> <td> 0.000</td> <td>    0.043</td> <td>    0.048</td>
</tr>
<tr>
  <th>radio</th>     <td>    0.1880</td> <td>    0.008</td> <td>   23.382</td> <td> 0.000</td> <td>    0.172</td> <td>    0.204</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>60.022</td> <th>  Durbin-Watson:     </th> <td>   2.081</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 148.679</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-1.323</td> <th>  Prob(JB):          </th> <td>5.19e-33</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 6.292</td> <th>  Cond. No.          </th> <td>    425.</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>The model assumes that the effect of increasing advertisment spent in one medium (e.g. TV) is independent of the amount spent on the other media. The effect on <code class="docutils literal notranslate"><span class="pre">sales</span></code> of spending one additional unit on <code class="docutils literal notranslate"><span class="pre">TV</span></code> is always <span class="math notranslate nohighlight">\(\beta_{tv}\)</span> irrespective of the amount spent on e.g. <code class="docutils literal notranslate"><span class="pre">radio</span></code>.</p>
<p>This assumption may be wrong and therefore the specified model may be incorrect.  For example, the amount spent on <code class="docutils literal notranslate"><span class="pre">radio</span></code> may actually  increase the effectiveness of <code class="docutils literal notranslate"><span class="pre">TV</span></code> advertisment.</p>
<p>This synergy (or dysynergy) effect is referred to as <strong>interaction effect</strong> in statistics.</p>
<p>One way of incorporating this interaction effect into a regression model is to combine variables multiplicatively such that</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_1X_2 + \epsilon\]</div>
<p>This can be rearranged such that:</p>
<p>\begin{equation}
\begin{split}
Y &amp;= \beta_0 + (\beta_1+\beta_3X_2)X_1 + \beta_2X_2 + \epsilon \
&amp; =  \beta_0 + \tilde{\beta}X_1 + \beta_2X_2 + \epsilon
\end{split}
\end{equation}</p>
<p>In this case <span class="math notranslate nohighlight">\(\tilde{\beta}\)</span> changes with <span class="math notranslate nohighlight">\(X_2\)</span>. Therefore, the effect of <span class="math notranslate nohighlight">\(X_1\)</span> on <span class="math notranslate nohighlight">\(Y\)</span> is no longer constant given that adjusting <span class="math notranslate nohighlight">\(X_2\)</span> changes <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>Let’s look at our dataset and include the interaction effect of <code class="docutils literal notranslate"><span class="pre">TV</span></code>x<code class="docutils literal notranslate"><span class="pre">radio</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;sales ~ TV + radio + TV:radio&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span> <span class="c1"># Note: TV:radio indicates that we want the interaction term</span>
<span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Intercept</th>
      <th>TV</th>
      <th>radio</th>
      <th>TV:radio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>230.1</td>
      <td>37.8</td>
      <td>8697.78</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>44.5</td>
      <td>39.3</td>
      <td>1748.85</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>17.2</td>
      <td>45.9</td>
      <td>789.48</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>151.5</td>
      <td>41.3</td>
      <td>6256.95</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>180.8</td>
      <td>10.8</td>
      <td>1952.64</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared:         </th> <td>   0.897</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   859.6</td>
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>4.83e-98</td>
</tr>
<tr>
  <th>Time:</th>                 <td>22:46:46</td>     <th>  Log-Likelihood:    </th> <td> -386.20</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   778.4</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   197</td>      <th>  BIC:               </th> <td>   788.3</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    2.9211</td> <td>    0.294</td> <td>    9.919</td> <td> 0.000</td> <td>    2.340</td> <td>    3.502</td>
</tr>
<tr>
  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.909</td> <td> 0.000</td> <td>    0.043</td> <td>    0.048</td>
</tr>
<tr>
  <th>radio</th>     <td>    0.1880</td> <td>    0.008</td> <td>   23.382</td> <td> 0.000</td> <td>    0.172</td> <td>    0.204</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>60.022</td> <th>  Durbin-Watson:     </th> <td>   2.081</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 148.679</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-1.323</td> <th>  Prob(JB):          </th> <td>5.19e-33</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 6.292</td> <th>  Cond. No.          </th> <td>    425.</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>We can see that the inclusion of the effedt increased <span class="math notranslate nohighlight">\(R^2_\text{adj}\)</span> significantly. Also the coefficient <code class="docutils literal notranslate"><span class="pre">TV:radio</span></code> (<span class="math notranslate nohighlight">\(\beta_3\)</span>) is highly significant.</p>
<p>Interpretation of <span class="math notranslate nohighlight">\(\beta_3\)</span>: increase in effectiveness of TV advertisment on radio advertisment (or the other way around).</p>
</div>
<div class="section" id="dealing-with-qualitative-data">
<h2>Dealing with qualitative data<a class="headerlink" href="#dealing-with-qualitative-data" title="Permalink to this headline">¶</a></h2>
<p>Up until now we have only worked with quantitative data, i.e. all variables in our models where numerical. However, this is not always the case. Explanatory variables can, of course, be qualitative.</p>
<p>For example, in our cars dataset we have a variable <code class="docutils literal notranslate"><span class="pre">origin</span></code>. The variable stores the information from which region the car is (US = 1, Europe = 2, Asia = 3).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cars</span><span class="p">[</span><span class="s2">&quot;origin&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 3, 2])
</pre></div>
</div>
</div>
</div>
<p>While the data is already encoded to be numerical the information it stores is still qualitative. For example, we cannot compare the data similar to numerial data. There is no numerical order and the distances between the values do not mean anything, i.e. 3 is not bigger than 1 in this case or a statement such as Asia is two more than US does not make sense.</p>
<p><strong>How do we deal with this kind of data in our regression model?</strong></p>
<p>If we deal with two categories (male/female) we can simply create a <em>dummy variable</em> (0/1) of the form:</p>
<p>\begin{equation}
x_i =\begin{cases}
1, &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th person is female}\
0, &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th person is male}
\end{cases}
\end{equation}</p>
<p>This results in the model:</p>
<p>\begin{equation}
y_i = \beta_0 + \beta_1x_i + \epsilon =\begin{cases}
\beta_0 + \beta_1 + \epsilon, &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th person is female}\
\beta_0 + \epsilon &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th person is male}
\end{cases}
\end{equation}</p>
<p>If we deal with more than two categories we need to create additional <em>dummy variables</em>. For example in our case we need two variables of the form:</p>
<p>\begin{equation}
x_{i1} =\begin{cases}
1, &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th car is from US}\
0, &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th car is not from US}
\end{cases}
\end{equation}</p>
<p>and\begin{equation}
x_{i2} =\begin{cases}
1, &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th car is from Asia}\
0, &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th car is not from Asia}
\end{cases}
\end{equation}</p>
<p>If we then use both variables in our model we can describe it as:</p>
<p>\begin{equation}
y_i = \beta_0 + \beta_1x_{i2} + \beta_2x_{i2} + \epsilon =\begin{cases}
\beta_0 + \beta_1 + \epsilon, &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th car is from US }\
\beta_0 + \beta_2 + \epsilon &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th car is from Asia}\
\beta_0  + \epsilon &amp; \text{if <span class="math notranslate nohighlight">\(i\)</span>th car is from Europe}
\end{cases}
\end{equation}</p>
<p>Let’s look at an example using our car dataset.</p>
<p>If we treat the variable <code class="docutils literal notranslate"><span class="pre">origin</span></code> just as a regular numerial value, the regression model will not yield sensical results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;mpg ~ origin&quot;</span><span class="p">,</span> <span class="n">cars</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span> <span class="c1"># origin NOT encoded categorically using dummy variables</span>
<span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.319</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.318</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   183.1</td>
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>1.81e-34</td>
</tr>
<tr>
  <th>Time:</th>                 <td>23:10:02</td>     <th>  Log-Likelihood:    </th> <td> -1285.8</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2576.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>   2583.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   14.8120</td> <td>    0.716</td> <td>   20.676</td> <td> 0.000</td> <td>   13.404</td> <td>   16.220</td>
</tr>
<tr>
  <th>origin</th>    <td>    5.4765</td> <td>    0.405</td> <td>   13.531</td> <td> 0.000</td> <td>    4.681</td> <td>    6.272</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>26.546</td> <th>  Durbin-Watson:     </th> <td>   0.829</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  30.323</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.678</td> <th>  Prob(JB):          </th> <td>2.60e-07</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.138</td> <th>  Cond. No.          </th> <td>    4.93</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>It does not make sense to say that asian cars (encoded as 3) have an impact of <span class="math notranslate nohighlight">\(3\times5.4765\)</span> on mpg, whereas as US cars only have an impact of <span class="math notranslate nohighlight">\(1\times5.4765\)</span></p>
<p>However, when encoding the variable as <em>dummy variable</em> the model itself is correctly specified and the interpretation is intuitive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;mpg ~ C(origin)&quot;</span><span class="p">,</span> <span class="n">cars</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span> <span class="c1"># origin encoded categorically using C(origin) </span>
<span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Intercept</th>
      <th>C(origin)[T.2]</th>
      <th>C(origin)[T.3]</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.332</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.328</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   96.60</td>
</tr>
<tr>
  <th>Date:</th>             <td>Thu, 12 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>8.67e-35</td>
</tr>
<tr>
  <th>Time:</th>                 <td>23:12:38</td>     <th>  Log-Likelihood:    </th> <td> -1282.2</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2570.</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   389</td>      <th>  BIC:               </th> <td>   2582.</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>      <td>   20.0335</td> <td>    0.409</td> <td>   49.025</td> <td> 0.000</td> <td>   19.230</td> <td>   20.837</td>
</tr>
<tr>
  <th>C(origin)[T.2]</th> <td>    7.5695</td> <td>    0.877</td> <td>    8.634</td> <td> 0.000</td> <td>    5.846</td> <td>    9.293</td>
</tr>
<tr>
  <th>C(origin)[T.3]</th> <td>   10.4172</td> <td>    0.828</td> <td>   12.588</td> <td> 0.000</td> <td>    8.790</td> <td>   12.044</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>26.330</td> <th>  Durbin-Watson:     </th> <td>   0.763</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  30.217</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.679</td> <th>  Prob(JB):          </th> <td>2.74e-07</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.066</td> <th>  Cond. No.          </th> <td>    3.16</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p><strong>How do we interpret the model results?</strong></p>
<p>The model yields two coefficients (besides the intercept):</p>
<ul class="simple">
<li><p>coefficient for <code class="docutils literal notranslate"><span class="pre">origin=2</span></code> is <span class="math notranslate nohighlight">\(7.57\)</span></p></li>
<li><p>coefficient for <code class="docutils literal notranslate"><span class="pre">origin=3</span></code> is <span class="math notranslate nohighlight">\(10.42\)</span></p></li>
</ul>
<p>They can be interpreted as follows.</p>
<ul class="simple">
<li><p>the fact that the car is European (ceteris paribus) increases mpg by <span class="math notranslate nohighlight">\(7.57\)</span></p></li>
<li><p>the fact that the car is Asian (ceteris paribus) increases mpg by <span class="math notranslate nohighlight">\(10.42\)</span></p></li>
<li><p>the US case is not modelled explicitly but we can deduct that the mpg for US cars is <span class="math notranslate nohighlight">\(7.57\)</span> lower compared to European cars and <span class="math notranslate nohighlight">\(10.42\)</span> lower compared to Asian cars (on average)</p></li>
</ul>
<p><strong>Creating dummy variables</strong></p>
<p>We have created dummy variables using <code class="docutils literal notranslate"><span class="pre">C(origin)</span></code> (C stands for categorical data). We can also do this (i) manually or (ii) using pandas.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># manually:</span>
<span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">dmatrices</span><span class="p">(</span><span class="s2">&quot;mpg ~ origin&quot;</span><span class="p">,</span> <span class="n">cars</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s2">&quot;dataframe&quot;</span><span class="p">)</span>
<span class="n">origin</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="s2">&quot;origin&quot;</span><span class="p">]</span>
<span class="n">X</span><span class="p">[</span><span class="s2">&quot;European&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">origin</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">X</span><span class="p">[</span><span class="s2">&quot;Asia&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">origin</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="s2">&quot;origin&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Intercept</th>
      <th>European</th>
      <th>Asia</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>387</th>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>388</th>
      <td>1.0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>389</th>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>390</th>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>391</th>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>392 rows × 3 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># using pandas</span>
<span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">origin</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2.0</th>
      <th>3.0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>387</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>388</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>389</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>390</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>391</th>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>392 rows × 2 columns</p>
</div></div></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters/chapter_analytics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="S04a_Estimation%26HyptothesisTesting.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Testen von Hypothesen</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="S06a_TidyData.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tidy Data</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      Durch Felix Zeidler<br/>
    
        &copy; Urheberrechte © 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>